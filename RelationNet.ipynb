{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "\n",
    "\n",
    "# setting hyperparameters\n",
    "parser = argparse.ArgumentParser(description='RelationNet')\n",
    "parser.add_argument('--gpu', '-g', \n",
    "                    type=int, \n",
    "                    default=0,\n",
    "                    help='GPU ID (-1 indicates CPU)')#Set the initial matrix\n",
    "parser.add_argument('--way', '-w',\n",
    "                    type=int, \n",
    "                    default=5,\n",
    "                    help='Number of way to train')\n",
    "parser.add_argument('--shot', '-s',\n",
    "                    type=int, \n",
    "                    default=20,\n",
    "                    help='Number of shot to train')\n",
    "parser.add_argument('--epoch',\n",
    "                    type=int, \n",
    "                    default=5000,\n",
    "                    help='Number of training time')\n",
    "parser.add_argument('--episode',\n",
    "                    type=int, \n",
    "                    default=100,\n",
    "                    help='Number of test time (maximum-600)')\n",
    "# create arg object\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading mini-Imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miniImage import miniImage\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "csv_file = './mini-imagenet/train.csv'\n",
    "root_dir = './mini-imagenet/train'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.92206, 0.92206, 0.92206], std=[0.08426, 0.08426, 0.08426])\n",
    "])\n",
    "\n",
    "trainset = miniImage(csv_file = csv_file,\n",
    "                     root_dir = root_dir,\n",
    "                     transform = transform,\n",
    "                     way = args.way)\n",
    "support_set = torch.utils.data.DataLoader(trainset,\n",
    "                                          batch_size=args.shot,\n",
    "                                          shuffle=True, \n",
    "                                          num_workers=6)\n",
    "query_set = torch.utils.data.DataLoader(trainset,\n",
    "                                        batch_size=1,\n",
    "                                        shuffle=True, \n",
    "                                        num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(args.gpu == -1):\n",
    "    device = torch.device('cpu')\n",
    "else:\n",
    "    device = torch.device('cuda:'+str(args.gpu) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "torch.cuda.empty_cache()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Feature Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNEncoder(nn.Module):\n",
    "    \"\"\"docstring for ClassName\"\"\"\n",
    "    def __init__(self):\n",
    "        super(CNNEncoder, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "                        nn.Conv2d(3,64,kernel_size=3,padding=0),\n",
    "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "                        nn.Conv2d(64,64,kernel_size=3,padding=0),\n",
    "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "                        nn.Conv2d(64,64,kernel_size=3,padding=1),\n",
    "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
    "                        nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "                        nn.Conv2d(64,64,kernel_size=3,padding=1),\n",
    "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
    "                        nn.ReLU())\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        return out # 64\n",
    "    \n",
    "encoder = CNNEncoder().to(device)\n",
    "encoder.eval()\n",
    "encoder.load_state_dict(torch.load('miniimagenet_feature_encoder_5way_5shot.pkl', map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Relation Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationNetwork(nn.Module):\n",
    "    \"\"\"docstring for RelationNetwork\"\"\"\n",
    "    def __init__(self):\n",
    "        super(RelationNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(64*19*19*2, 512)\n",
    "        self.pr1 = nn.PReLU()\n",
    "        self.fc2 = nn.Linear(512, 64)\n",
    "        self.pr2 = nn.PReLU()\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = x.view(x.size(0),-1)\n",
    "        out = self.pr1(self.fc1(out))\n",
    "        out = self.pr2(self.fc2(out))\n",
    "        out = torch.sigmoid(self.fc3(out))\n",
    "        return out\n",
    "    \n",
    "relation_net = RelationNetwork().to(device)\n",
    "relation_net.load_state_dict(torch.load('miniimagenet_relation_net_5way_5shot.pkl', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(relation_net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Epoch\n",
    "\"\"\"\n",
    "running_loss = 0.0\n",
    "TP = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "TN = 0\n",
    "for epoch in range(args.epoch):\n",
    "        sample = next(iter(support_set))\n",
    "        sample_imgs = sample['data'].to(device) # [shot x 3 x 84 x 84]\n",
    "        sample_labels = sample['label'] # [shot]        \n",
    "        sample_features = encoder(sample_imgs)  # [shot, 64, 19, 19]\n",
    "        \n",
    "        \"\"\"\n",
    "        Episode\n",
    "        \"\"\"\n",
    "        for episode, query in zip(range(args.episode), query_set):\n",
    "            query_imgs = query['data'].to(device) # [1 x 3 x 84 x 84]\n",
    "            query_labels = query['label'] # [1]\n",
    "            query_features = encoder(query_imgs) #[1 x 64 x 19 x 19] \n",
    "            \n",
    "            # copy arg.shot times\n",
    "            query_features = query_features.repeat(args.shot, 1, 1, 1) #[shot x 64 x 19 x 19]\n",
    "            query_labels = query_labels.repeat(args.shot) #[shot]\n",
    "\n",
    "            # concatenate sample feautres and query features\n",
    "            inputs = torch.cat([sample_features, query_features], dim=1) #[shot x 128 x 19 x 19]\n",
    "            labels = torch.zeros((args.shot), dtype=torch.float).to(device) #[shot]\n",
    "            labels[query_labels == sample_labels] = 1\n",
    "\n",
    "            \"\"\"\n",
    "            Training\n",
    "            \"\"\"\n",
    "            optimizer.zero_grad()                    \n",
    "            outputs = relation_net(inputs).view(-1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "    \n",
    "            for i, class_prob in enumerate(outputs):\n",
    "                if(class_prob > 0.9):\n",
    "                    if(sample_labels[i] == query_labels[0]):\n",
    "                        TP += 1\n",
    "                    else:\n",
    "                        FP += 1\n",
    "                else:\n",
    "                    if(sample_labels[i] == query_labels[0]):\n",
    "                        FN += 1\n",
    "                    else:\n",
    "                        TN += 1\n",
    "            \n",
    "            if(episode % args.episode == args.episode-1):\n",
    "                print('[{:d}, {:3d}] loss: {:.3f}'.format(\n",
    "                      epoch + 1, episode+1, running_loss/args.episode))\n",
    "                running_loss = 0.0\n",
    "    \n",
    "        if (epoch+1)*(episode+1) % (args.episode*100) == 0:\n",
    "            print('------------------------------------------')\n",
    "            print('Precision = {:5%}'.format(TP/(TP+FP) if (TP+FP)!=0 else 0))\n",
    "            print('Sensitivity = {:5%}'.format(TP/(TP+FN) if (TP+FN)!=0 else 0))\n",
    "            print('Accuracy = {:5%}'.format((TP+TN)/(TP+FP+FN+TN)))\n",
    "            print('------------------------------------------')\n",
    "            TP = 0\n",
    "            FP = 0\n",
    "            FN = 0\n",
    "            TN = 0\n",
    "            trainset.sample_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(relation_net.state_dict(), 'miniimagenet_relation_net_5way_5shot.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
